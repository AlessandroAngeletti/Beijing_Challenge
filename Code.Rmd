---
title: "Group 13 - Final Project: Beijing"
author: "Study Group 13"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: cosmo
    highlight: breezedark
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)
# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
#Using this space to load libraries
library(vroom)
library(dplyr)
library(knitr)
library(mosaic)
library(skimr)
library(ggplot2)
library(GGally)
library(janitor)
library(readr)
library(leaflet)
library(scales)
library(broom)
library(huxtable)
library(car)
library(ggfortify)
library(rsample)
library(ggridges)
library(patchwork)
library(kableExtra)
library(patchwork)
options('huxtable.knit_print_df' = FALSE)
```


# Executive Summary

# Background: Airbnb in Beijing

# Exploratory Data Analysis

First we have to download the data.

```{r weather_data, cache=TRUE}
data <- vroom::vroom("listings.csv.gz") %>% 
  clean_names()
```

## Raw Data Exploration 

```{r}
# Let's have a look at what we're dealing with!
glimpse(data)
```

From this output we can see that we have
+ just over 36 thousand observations (or Airbnb listings) in Beijing in the data set
+ 106 different variables included in the data
+ these variables are a mixture of 'double', 'character', 'logic' and 'date'
+ straightaway we can see that some of our 'price' variables include dollar signs ($) and are down as 'character' variables rather than 'double' variables

Since this is a large data set with a lot going on, we will compute some summary statistics on key variables

## Summary Statistics and Missing Values

```{r}
  listings <- data %>% 
  
  #Lets pick the variables we need
  select(c(price,
           cleaning_fee,
           extra_people,
           room_type,
           property_type,
           number_of_reviews,
           review_scores_rating,
           longitude,
           latitude,
           neighbourhood,
           minimum_nights,
           guests_included,
           bathrooms,
           bedrooms,
           beds,
           accommodates,
           host_is_superhost,
           neighbourhood_cleansed,
           cancellation_policy,
           listing_url,
           is_location_exact,
           security_deposit,
           review_scores_cleanliness,
           instant_bookable,
           is_business_travel_ready
           )
         ) %>% 

  #Removing dollar signs and changing into numerical variables
  
  mutate(
 
    #Changing Price from chr to dbl
    
    price = parse_number(price),
    
    #Changing Cleaning Fee from chr to dbl
    
    cleaning_fee = parse_number(cleaning_fee),
    
    #Changing Extra People fee from chr to dbl
    
    extra_people = parse_number(extra_people),
    
    #Changing Security Deposit from chr to dbl
    
    security_deposit = parse_number(security_deposit)
  )
```
Now that we have all the variables in the format required, we can move on to the quality of the data.

### Removing Missing Values
```{r}
# Check which variables have lots of missing values (NA's)
listings %>% 
  skim() %>% 
  kbl() %>% 
  kable_styling()
```

> Here we can see that <cleaning_fee> has an extremely high number of missing values or <NA> values.
> This is most likely due to some properties including a cleaning fee within the price, and 
> then not listing the cleaning fee as '$0'.
> A similar issue arises with security deposit.
  + In consumer psychology, additional costs are often viewed negatively

```{r}
data_cleaned <- listings %>% 
  
  # In order to handle the high volume of NA's in cleaning_fee, we will change these values to a 0
  
  mutate(
    cleaning_fee = case_when(
      is.na(cleaning_fee) ~ 0,
      TRUE ~ cleaning_fee
        ),
  # We apply the same logic to the security_deposit variable
  
    security_deposit = case_when(
      is.na(security_deposit) ~ 0,
      TRUE ~ security_deposit
        )
    )

# Let's skim the cleaning_fee variable to see if we have succeeded
data_cleaned %>% 
skim(cleaning_fee) %>% 

  # the kable package is used to format the resulting tables in a more visually appealing way
  kbl() %>% 
  kable_styling()
```



## Visualising The Data
### Numerical Data

```{r}

# Using patchwork to create a visualization of density for all numerical variables
p1 <- ggplot(data = data_cleaned, aes(x = price)) +
  geom_density() +
  theme_bw()
```

Before creating plots for all other numerical variables, let's check the readability

```{r}
p1

#Some of the x-axis for the data mean that it is difficult to get a full picture of the variability in the variables

p1a <- ggplot(data = data_cleaned, aes(x = price)) +
  geom_density() +
  
  #Here we add a limit to the x-axis, where the maximum value is 10000. We add this to most of the plots, where necessary
  
  xlim(0, 10000) +
  theme_bw() 

p2a <- ggplot(data = data_cleaned, aes(x = cleaning_fee)) +
  geom_density() +
  xlim(0, 300) +
  theme_bw() 

p3a <- ggplot(data = data_cleaned, aes(x = guests_included)) +
  geom_density() +
  xlim(0, 8) +
  theme_bw()

p4a <- ggplot(data = data_cleaned, aes(x = extra_people)) +
  geom_density() +
  xlim(0, 400) +
  theme_bw()

p5a <- ggplot(data = data_cleaned, aes(x = number_of_reviews)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw()

p6a <- ggplot(data = data_cleaned, aes(x = review_scores_rating)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() 

p7a <- ggplot(data = data_cleaned, aes(x = minimum_nights)) +
  geom_density() +
  xlim(0, 150) +
  theme_bw() 

p8a <- ggplot(data = data_cleaned, aes(x = accommodates)) +
  geom_density() +
  theme_bw()

p9a <- ggplot(data = data_cleaned, aes(x = beds)) +
  geom_density() +
  xlim(0, 20) +
  theme_bw()

p10a <- ggplot(data = data_cleaned, aes(x = bathrooms)) +
  geom_density() +
  xlim(0, 20) +
  theme_bw()

p11a <- ggplot(data = data_cleaned, aes(x = bedrooms)) +
  geom_density() +
  xlim(0, 15) +
  theme_bw()

p1a + p2a + p3a + p4a + p5a + p6a + p7a + p8a + p9a + p10a + p11a
```

```{r, fig.width=15, fig.height=15}

# using ggpairs to plot a correlation matrix
data_cleaned %>% 
  select(c(price, cleaning_fee, guests_included, 
           extra_people, number_of_reviews, review_scores_rating, 
           minimum_nights, accommodates, beds, bathrooms, bedrooms, security_deposit)
         ) %>% 
    ggpairs()

```
> Notable correlations with price are:
1. Accomodates (number of people the listing can accomodate)
2. Bedrooms (number of bedrooms at the listing)
3. Bathrooms (number of bathrooms at the listing)
4. Beds (number of beds at the listing)
5. Cleaning fee (additional flat cleaning fee)
6. Guests included (number of guests included in the price and exempt from <extra_people> fee)
7. Extra People (charge per night for each person over the <guests_included>)

> Notable correlations between variables:
1. Accomodates/Beds/Bathrooms/Bedrooms/ - the greater the number of rooms, the greater the number of guests it can accommodate

> These plots demonstrate????

### Categorical Data

Some of the character variables have lots of different values, e.g. <property_type>. Here we look at cleaning this to make it more manageable.

```{r}

data_cleaned %>% 
  # Counting the frequency of property types
  count(property_type) %>% 
  # Arranging them into descending order by frequency
  arrange(desc(n))

```

We're now classifying different types of properties into 5 groups - the 4 most prominent ones and remaining smaller categories labeled as 'Other'.


```{r}

cleaning <- data_cleaned %>%
      # creating a new variable 'prop_type_simplified' that groups property types into one of 5 categories. For example, "Boutique hotel" will now come under "Other"

  mutate(prop_type_simplified = case_when(
    
        # Here we specify that if property_type is equal to the top 4 types, then we pass through the property_type value
    
        property_type %in% c("Apartment","Condominium", "House","Loft") ~ property_type, 
        
        # This specifies that if the property_type value doesn't meet this criteria, the new variable will equal 'Other
        
        TRUE ~ "Other"
  ))
```

Now that our categorical variables are cleaned, we can inspect the variability as we did with the numerical variables, this time using bar plots.
Plotting property types, room types, super host status and cancellation policy, to analyse their distribution. 
```{r}
# Simple ggplot code specifying x variable, visualisation type and theme
# using patchwork to plot distribution of different variables

p12 <- ggplot(data = cleaning, aes(x = prop_type_simplified)) +
  geom_bar() +
  theme_bw()

p13 <- ggplot(data = cleaning, aes(x = room_type)) +
  geom_bar() +
  theme_bw()

p14 <- ggplot(data = cleaning, aes(x = host_is_superhost)) +
  geom_bar() +
  theme_bw()

p15 <- ggplot(data = cleaning, aes(x = cancellation_policy)) +
  geom_bar() +
  theme_bw()

# Using patchwork to create a clean grid of the bar plots

p12 + p13 + p14 + p15
```

> commentary needed on bar plots


### Preliminary Correlation Analysis

```{r}
#Here we can explore the correlation between our numerical variables

data_numerical <- data_cleaned %>% 
  
  #First we select the variables we want to plot against each other
  
  select(c(price, cleaning_fee, guests_included, extra_people, number_of_reviews, review_scores_rating, minimum_nights,
           accommodates, beds, bathrooms, bedrooms)) %>% 
  
  #Next we use the ggpairs function to plot a grid of scatter plots with correlation coefficients
  
  ggpairs() +
  theme_bw()

data_numerical
```
> Notable correlations with price are:
1. Accomodates (number of people the listing can accomodate)
1. Bedrooms (number of bedrooms at the listing)
1. Bathrooms (number of bathrooms at the listing)
1. Beds (number of beds at the listing)
1. Cleaning fee (additional flat cleaning fee)
1. Guests included (number of guests included in the price and exempt from <extra_people> fee)
1. Extra People (charge per night for each person over the <guests_included>)

>Notable correlations between variables:
1. Accomodates/Beds/Bathrooms/Bedrooms/ - this makes sense because...????
1. 


## Mapping

As we are looking at data over a geographical region, it can be helpful to see the geospatial spread of the Airbnb listings. Here we use the leaflet package to map our longitude and latitude data onto a map.

```{r}
# Using the leaflet package

leaflet(data = filter(cleaning, minimum_nights <= 4)) %>% 
  
# Adding the map to lie beneath the data points
  
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  
# Adding our listing data as points on the map
  
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

# Regression Analysis
## Preparation for Regression Analysis

In order to run a regression model, we will transform our price data into a approximately 'normal' distribution.
```{r}

# We want to use log to transform our data into a more normal looking distribution of data, let's first see how the distribution would look

cleaning %>% 
  ggplot() +
  geom_density(aes(x = minimum_nights)) +
  
# Use this to transform the x-axis by log10  

  scale_x_log10()
cleaning
```

As we are looking to model the price of an Airbnb in Beijing for travel/tourism, we should look into the minimum_nights variable. This variable states the minimum number of nights you are able to to book the listing for.

```{r}
# Visualise the frequency of minimum nights

# arranging listings by minimum_nights
cleaning %>% 
  count(minimum_nights) %>% 
  
# Arrange in descending order of frequency
  
  arrange(desc(n))

# calculating summary statistics for the distribution of minimum_nights
favstats(data = cleaning , ~ minimum_nights) %>% 
  kbl() %>% 
  kable_styling()
```

**From the above, we can infer the following -**
+ The most common values for 'minimum nights' are 1 to 3 nights as they account for 92.1% of total listings. The next biggest category is '30 minimum nights' (2.26% of total listings)
+ 30 minimum nights seem rather strange - maybe the people booking the Airbnbs are visiting Beijing for reasons other than leisure/ travel. For example, they may prefer Airbnbs as a budget friendly alternative to hotels for longer stays intended for business-related work, etc.
+ There are 61 listings for minimum nights of 365 days (1 year) as well which implies that some Airbnbs are more for the purpose of long-term renting or sub-letting.  


## Creating Variable to Model

```{r, Options(scipen = 999), fig.width=10, fig.height =15}
neighbourhoodring <- vroom::vroom("neighbourhoodring.csv")

regression_data <-  cleaning %>% 
  # filter for minimum nights at most 4
  filter(minimum_nights<=4) %>% 
  # New variable that computes the price of 2 people booking an Airbnb for 4 nights
  # Note: extra_people charge per 1 extra person applied per night when no. of guests > guests_included
  left_join(., neighbourhoodring, by = "neighbourhood", copy = TRUE) %>%
  mutate(price_for_4_notlog = case_when(
      guests_included < 2 ~ cleaning_fee + (4 * (price + extra_people)),
      TRUE ~ cleaning_fee + (4 * price)
    ),
    price_4_nights = log(price_for_4_notlog + 0.00001),
    #New variable that classifies neighborhood into 5 areas according to Beijing's geographical characteristic
    #The 5 areas are Ring 2-6  
    neighbourhood_simplified = case_when(
      Ring == "2" ~ "Ring 2",
      Ring == "3" ~ "Ring 3",
      Ring == "4" ~ "Ring 4",
      Ring == "5" ~ "Ring 5",
      TRUE ~ "Ring 6"
    )) %>% 
  subset(., select = -Ring)
  
  regression_data
  
  # ggplot for price of four nights
ggplot(data = regression_data, aes(x = price_for_4_notlog)) +

  geom_histogram() +
  xlim(0, 40000)

# ggplot for log of price of four nights
ggplot(data = regression_data, aes(x = price_4_nights)) +
  geom_density() 
      # we use loggy-loggy to effectively change the case from a unit change to a percentage change

# look at cleaned data for regression models
glimpse(regression_data)

#regression_data %>% 
  #select(-c(room_type, property_type, longitude, latitude, neighbourhood, neighbourhood_cleansed, cancellation_policy, #listing_url, prop_type_simplified)) %>% 
  #ggpairs()
```

### Building Linear Regression Models

## Building Regression Models

```{r}

# model 1 with a few variables - reviews and property types
model1 <- lm(price_4_nights ~ 
               prop_type_simplified + number_of_reviews + review_scores_rating,
             regression_data)

model1 %>% tidy(conf.int=TRUE) %>% 
  kbl() %>% 
  kable_styling()

model1 %>% glance() %>% 
  kbl() %>% 
  kable_styling()
```

Here, property type is a categorical variable - it has five categories and therefore makes up 4 dummy variables in the regression model. For example, for 'House', `prop_type_simplifiedHouse` = 1 (`prop_type_simplifiedCondominium` = 0 and `prop_type_simplifiedOther` = 0) and the intercept term would be ~7.11. The intercept term for 'Apartment' would be ~6.91.

Other variables such as `number_of_reviews` and `review_scores_rating` are statistically significant and explain the variation in `price_4_nights`, however, a point worth noting is that additional `number_of_reviews` do not lead to an increase in cost for 4 nights as the reviews may not necessarily be good reviews. On the other hand, `review_scores_rating` have a positive effect on price for 4 nights which means that properties with a higher score/ rating would cost more.  


```{r}
model2 <- lm(price_4_nights ~ 
               prop_type_simplified + number_of_reviews + review_scores_rating + room_type, 
             regression_data)
model2 %>% tidy(conf.int=TRUE)
model2 %>% glance()
```

> The following variables are statistically insignificant:
1. prop_type_simplifiedCondominium
1. prop_type_simplifiedLoft
1. prop_type_simplifiedServiced apartment
1. review_scores_rating

## comparing model 1 and model 2
```{r}
huxreg(model1, model2,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')
```

> interpretation of the coefficients of review scores rating and prop_type_simplified with respect to price_for_4_notlog

## adding more variables  

```{r}
#
model3 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates , 
             regression_data
            )

model3 %>% tidy(conf.int=TRUE)
model3 %>% glance()

# excluded beds but realised let's keep it
# model4 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + accommodates , 
#              regression_data
#             )
# 
# model4 %>% tidy(conf.int=TRUE)
# model4 %>% glance()
```
> hypothesize that being a super host would significantly impact price of 4 nights 

```{r}
# superhost or not
model5 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost, 
             regression_data
            )

model5 %>% tidy(conf.int=TRUE)
model5 %>% glance()
```
> our hypothesis is rejected as the variable is insignificant. drop host_is_superhost, does not matter heheh. add some logic as to why people visiting Beijing don't care if their host is a superhost. 

```{r}
# We know that superhost is not relevant, however, is it relevant if its intertwined with the number of reviews?
model6 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost*number_of_reviews, 
             regression_data
            )

model6 %>% tidy(conf.int=TRUE)
model6 %>% glance()
```
> Nope

```{r}
# We know that superhost is not relevant, however, is it relevant if its intertwined with the review ratings?
model7 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost*review_scores_rating, 
             regression_data
            )

model7 %>% tidy(conf.int=TRUE)
model7 %>% glance()
```
> Nope

next variable 

```{r}
model8 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact, 
             regression_data
            )

model8 %>% tidy(conf.int=TRUE)
model8 %>% glance()
```

We now add the neighbourhood element

```{r}
model9 <- lm(price_4_night ~ 
               prop_type_simplified + 
               number_of_reviews + 
               review_scores_rating + 
               room_type + 
               bedrooms + 
               bathrooms + 
               beds + 
               accommodates + 
               is_location_exact + 
               neighbourhood_simplified,
              regression_data
             )

model9 %>% tidy(conf.int=TRUE)
model9 %>% glance()

```

We now add the cancellation policy stuff

```{r}
model10 <- lm(price_4_night ~ 
                prop_type_simplified + 
                number_of_reviews + 
                review_scores_rating + 
                room_type + 
                bedrooms + 
                bathrooms + 
                beds + 
                accommodates + 
                is_location_exact +
                neighbourhood_simplified +
                cancellation_policy,
                regression_data
            )

model10 %>% tidy(conf.int=TRUE)
model10 %>% glance()
```
> Cancelation policy does not seem to significantly affect the price

```{r}
huxreg(model3, model5, model8, model10,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')
```

```{r}

# regression_data %>% 
#   select(c(price_4_nights, 
#            review_scores_cleanliness, security_deposit)) %>% 
# ggpairs()

model11 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy + review_scores_cleanliness, 
             regression_data
            )

model11 %>% tidy(conf.int=TRUE)
model11 %>% glance()

model12 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy + instant_bookable,
             regression_data
            )

model12 %>% tidy(conf.int=TRUE)
model12 %>% glance()

model13 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + security_deposit,
             regression_data
            )

model13 %>% tidy(conf.int=TRUE)
model13 %>% glance()

#################
huxreg(model11, model12, model13,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')

# 

car::vif(model1)
car::vif(model2)
car::vif(model13)

########### https://www.displayr.com/variance-inflation-factors-vifs/ USE THIS TO EXPLAIN - ex: beds/baths/accommodates - but none of the VIFs is high enough to suggest collinearity so we're good

```


## Diagnostics, collinearity, summary tables

```{r}

autoplot(model1)

```

```{r}

reading_week <- regression_data %>% 
  filter(prop_type_simplified=="Apartment", 
         room_type=="Private room", 
         number_of_reviews >=10,
         review_scores_rating >=90)

reading_week

set.seed(6789)

train_test_split <- initial_split(reading_week, prop=0.75)
reading_week_train <- training(train_test_split)
reading_week_test <- testing(train_test_split)

rmse_train <- reading_week_train %>% 
  mutate(
    predictions = predict(model1, .)
  ) %>% 
  summarise(
    sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

rmse_train

rmse_test <- reading_week_test %>% 
  mutate(predictions = predict(model1, .)) %>% 
  summarise(
    sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

rmse_test

```
