---
title: "Group 13 - Final Project: Beijing"
author: "Study Group 13"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: cosmo
    highlight: breezedark
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)
# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
#Using this space to load libraries
library(vroom)
library(dplyr)
library(knitr)
library(mosaic)
library(skimr)
library(ggplot2)
library(GGally)
library(janitor)
library(readr)
library(leaflet)
library(scales)
library(broom)
library(huxtable)
library(car)
library(ggfortify)
library(rsample)
library(ggridges)
library(patchwork)
library(kableExtra)
options('huxtable.knit_print_df' = FALSE)
```

# Executive Summary

# Background: Airbnb in Beijing

# Exploratory Data Analysis

First we have to download the data.

```{r weather_data, cache=TRUE}
data <- vroom::vroom("listings.csv.gz") %>% 
  clean_names()
```

## Raw Data Exploration 

```{r}
# Let's have a look at what we're dealing with!
glimpse(data)
```

From this output we can see that we have
+ just over 36 thousand observations (or Airbnb listings) in Beijing in the data set
+ 106 different variables included in the data
+ these variables are a mixture of 'double', 'character', 'logic' and 'date'
+ straightaway we can see that some of our 'price' variables include dollar signs ($) and are down as 'character' variables rather than 'double' variables

Since this is a large data set with a lot going on, we will compute some summary statistics on key variables

## Summary Statistics and Missing Values

```{r}
  listings <- data %>% 
  
  #Lets pick the variables we need
  select(c(price,
           cleaning_fee,
           extra_people,
           room_type,
           property_type,
           number_of_reviews,
           review_scores_rating,
           longitude,
           latitude,
           neighbourhood,
           minimum_nights,
           guests_included,
           bathrooms,
           bedrooms,
           beds,
           accommodates,
           host_is_superhost,
           neighbourhood_cleansed,
           cancellation_policy,
           listing_url,
           is_location_exact,
           security_deposit,
           review_scores_cleanliness,
           instant_bookable,
           is_business_travel_ready
           )
         ) %>% 

  #Removing dollar signs and changing into numerical variables
  
  mutate(
 
    #Changing Price from chr to dbl
    
    price = parse_number(price),
    
    #Changing Cleaning Fee from chr to dbl
    
    cleaning_fee = parse_number(cleaning_fee),
    
    #Changing Extra People fee from chr to dbl
    
    extra_people = parse_number(extra_people),
    
    #Changing Security Deposit from chr to dbl
    
    security_deposit = parse_number(security_deposit)
  )
```
Now that we have all the variables in the format required, we can move on to the quality of the data.

### Removing Missing Values
```{r}
# Check which variables have lots of missing values (NA's)
listings %>% 
  skim() %>% 
  kbl() %>% 
  kable_styling()
```

> Here we can see that <cleaning_fee> has an extremely high number of missing values or <NA> values.
> This is most likely due to some properties including a cleaning fee within the price, and 
> then not listing the cleaning fee as '$0'.
> A similar issue arises with security deposit.
  + In consumer psychology, additional costs are often viewed negatively

```{r}
data_cleaned <- listings %>% 
  
  # In order to handle the high volume of NA's in cleaning_fee, we will change these values to a 0
  
  mutate(
    cleaning_fee = case_when(
      is.na(cleaning_fee) ~ 0,
      TRUE ~ cleaning_fee
        ),
  # We apply the same logic to the security_deposit variable
  
    security_deposit = case_when(
      is.na(security_deposit) ~ 0,
      TRUE ~ security_deposit
        )
    )

# Let's skim the cleaning_fee variable to see if we have succeeded
data_cleaned %>% 
skim(cleaning_fee) %>% 

  # the kable package is used to format the resulting tables in a more visually appealing way
  kbl() %>% 
  kable_styling()
```



## Visualising The Data
### Numerical Data

```{r}

# Using patchwork to create a visualization of density for all numerical variables
p1 <- ggplot(data = data_cleaned, aes(x = price)) +
  geom_density() +
  theme_bw()
```

Before creating plots for all other numerical variables, let's check the readability

```{r}
p1

#Some of the x-axis for the data mean that it is difficult to get a full picture of the variability in the variables

p1a <- ggplot(data = data_cleaned, aes(x = price)) +
  geom_density() +
  
  #Here we add a limit to the x-axis, where the maximum value is 10000. We add this to most of the plots, where necessary
  
  xlim(0, 10000) +
  theme_bw() 

p2a <- ggplot(data = data_cleaned, aes(x = cleaning_fee)) +
  geom_density() +
  xlim(0, 300) +
  theme_bw() 

p3a <- ggplot(data = data_cleaned, aes(x = guests_included)) +
  geom_density() +
  xlim(0, 8) +
  theme_bw()

p4a <- ggplot(data = data_cleaned, aes(x = extra_people)) +
  geom_density() +
  xlim(0, 400) +
  theme_bw()

p5a <- ggplot(data = data_cleaned, aes(x = number_of_reviews)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw()

p6a <- ggplot(data = data_cleaned, aes(x = review_scores_rating)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() 

p7a <- ggplot(data = data_cleaned, aes(x = minimum_nights)) +
  geom_density() +
  xlim(0, 150) +
  theme_bw() 

p8a <- ggplot(data = data_cleaned, aes(x = accommodates)) +
  geom_density() +
  theme_bw()

p9a <- ggplot(data = data_cleaned, aes(x = beds)) +
  geom_density() +
  xlim(0, 20) +
  theme_bw()

p10a <- ggplot(data = data_cleaned, aes(x = bathrooms)) +
  geom_density() +
  xlim(0, 20) +
  theme_bw()

p11a <- ggplot(data = data_cleaned, aes(x = bedrooms)) +
  geom_density() +
  xlim(0, 15) +
  theme_bw()

p1a + p2a + p3a + p4a + p5a + p6a + p7a + p8a + p9a + p10a + p11a
```

> These plots demonstrate????

### Categorical Data

Some of the character variables have lots of different values, e.g. <property_type>. Here we look at cleaning this to make it more manageable.

```{r}
data_cleaned %>% 
  
  # Counting the frequency of property types
  count(property_type) %>% 
  
  # Arranging them into descending order by frequency
  arrange(desc(n))

```

A high percentage of listings fall under the top 4 property types. Therefore, it makes sense to create a simplified variable that only includes the most frequent types, and group everything else into an 'other' group.

```{r}
cleaning <- data_cleaned %>%
  
  # Use mutate to create the new simplified variable
  
  mutate(prop_type_simplified = case_when(
    
        # Here we specify that if property_type is equal to the top 4 types, then we pass through the property_type value
    
        property_type %in% c("Apartment","Condominium", "House","Loft") ~ property_type, 
        
        # This specifies that if the property_type value doesn't meet this criteria, the new variable will equal 'Other
        
        TRUE ~ "Other"
  ))
```

Now that our categorical variables are cleaned, we can inspect the variability as we did with the numerical variables, this time using bar plots.

```{r}
# Simple ggplot code specifying x variable, visualisation type and theme

p12 <- ggplot(data = cleaning, aes(x = prop_type_simplified)) +
  geom_bar() +
  theme_bw()

p13 <- ggplot(data = cleaning, aes(x = room_type)) +
  geom_bar() +
  theme_bw()

p14 <- ggplot(data = cleaning, aes(x = host_is_superhost)) +
  geom_bar() +
  theme_bw()

p15 <- ggplot(data = cleaning, aes(x = cancellation_policy)) +
  geom_bar() +
  theme_bw()

# Using patchwork to create a clean grid of the bar plots

p12 + p13 + p14 + p15
```

> commentary needed on bar plots


### Preliminary Correlation Analysis

```{r}
#Here we can explore the correlation between our numerical variables

data_numerical <- data_cleaned %>% 
  
  #First we select the variables we want to plot against each other
  
  select(c(price, cleaning_fee, guests_included, extra_people, number_of_reviews, review_scores_rating, minimum_nights,
           accommodates, beds, bathrooms, bedrooms)) %>% 
  
  #Next we use the ggpairs function to plot a grid of scatter plots with correlation coefficients
  
  ggpairs() +
  theme_bw()

data_numerical
```
> Notable correlations with price are:
1. Accomodates (number of people the listing can accomodate)
1. Bedrooms (number of bedrooms at the listing)
1. Bathrooms (number of bathrooms at the listing)
1. Beds (number of beds at the listing)
1. Cleaning fee (additional flat cleaning fee)
1. Guests included (number of guests included in the price and exempt from <extra_people> fee)
1. Extra People (charge per night for each person over the <guests_included>)

>Notable correlations between variables:
1. Accomodates/Beds/Bathrooms/Bedrooms/ - this makes sense because...????
1. 


## Mapping

As we are looking at data over a geographical region, it can be helpful to see the geospatial spread of the Airbnb listings. Here we use the leaflet package to map our longitude and latitude data onto a map.

```{r}
# Using the leaflet package

leaflet(data = filter(cleaning, minimum_nights <= 4)) %>% 
  
# Adding the map to lie beneath the data points
  
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  
# Adding our listing data as points on the map
  
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

# Regression Analysis
## Preparation for Regression Analysis

In order to run a regression model, we will transform our price data into a approximately 'normal' distribution.
```{r}

# We want to use log to transform our data into a more normal looking distribution of data, let's first see how the distribution would look

cleaning %>% 
  #filter(minimum_nights <= 4) %>% 
  ggplot() +
  geom_density(aes(x = minimum_nights)) +
  
# Use this to transform the x-axis by log10  

  scale_x_log10()

cleaning
```

As we are looking to model the price of an Airbnb in Beijing for travel/tourism, we should look into the minimum_nights variable. This variable states the minimum number of nights you are able to to book the listing for.

```{r}
# Visualise the frequency of minimum nights

cleaning %>% 
  count(minimum_nights) %>% 
  
# Arrange in descending order of frequency
  
  arrange(desc(n))

favstats(data = cleaning , ~ minimum_nights) %>% 
  kbl() %>% 
  kable_styling()
```


> The most common values are between 1 to 3 nights.

> <minimum_nights> over 30 days is rather strange as by this point you're no longer looking to be a tourist and rather live there



## Creating Variable to Model

```{r, Options(scipen = 999), fig.width=10, fig.height =15}

regression_data <-  cleaning %>% 
  # New variable that computes the price of 2 people sleeping in a ... for 4 nights
  # Note that the extra people charge is applied per night when number of guests exceed the guests included variable
  # aka if its less than 2
  mutate(price_4_nights = case_when(
      guests_included < 2 ~ cleaning_fee + (4 * (price + extra_people)),
      TRUE ~ cleaning_fee + (4 * price)
    )
  ) %>% 
  mutate(
    price_4_night = log(price_4_nights + 0.000000001)  #searchable
  )

regression_data

# ggplot for price_4_nights
ggplot(data = regression_data, aes(x = price_4_nights)) +
  geom_histogram() +
  xlim(0, 40000)

# ggplot for log of price_4_nights
ggplot(data = regression_data, aes(x = price_4_night)) +
  geom_density() 

# We use loggy-loggy because we effectively change the case from a unit change to a percent change

# ggpairs for correlation
glimpse(regression_data)

#regression_data %>% 
  #select(-c(room_type, property_type, longitude, latitude, neighbourhood, neighbourhood_cleansed, cancellation_policy, #listing_url, prop_type_simplified)) %>% 
  #ggpairs()
```
> Johanna's writing about ggpairs

## Building Regression Models

```{r}
model1 <- lm(data = regression_data, price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating)
model1 %>% tidy(conf.int=TRUE)
model1 %>% glance() %>% 
  kbl() %>% 
  kable_styling()
```

> The following variables are statistically insignificant:
1. prop_type_simplifiedCondominium
1. prop_type_simplifiedLoft
1. review_scores_rating


```{r}
model2 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type, regression_data)
model2 %>% tidy(conf.int=TRUE)
model2 %>% glance()
```

> The following variables are statistically insignificant:
1. prop_type_simplifiedCondominium
1. prop_type_simplifiedLoft
1. prop_type_simplifiedServiced apartment
1. review_scores_rating

## comparing model 1 and model 2
```{r}
huxreg(model1, model2,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')
```

> interpretation of the coefficients of review scores rating and prop_type_simplified with respect to price_4_nights

## adding more variables  

```{r}
#
model3 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates , 
             regression_data
            )

model3 %>% tidy(conf.int=TRUE)
model3 %>% glance()

# excluded beds but realised let's keep it
# model4 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + accommodates , 
#              regression_data
#             )
# 
# model4 %>% tidy(conf.int=TRUE)
# model4 %>% glance()
```
> hypothesize that being a super host would significantly impact price of 4 nights 

```{r}
# superhost or not
model5 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost, 
             regression_data
            )

model5 %>% tidy(conf.int=TRUE)
model5 %>% glance()
```
> our hypothesis is rejected as the variable is insignificant. drop host_is_superhost, does not matter heheh. add some logic as to why people visiting Beijing don't care if their host is a superhost. 

```{r}
# We know that superhost is not relevant, however, is it relevant if its intertwined with the number of reviews?
model6 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost*number_of_reviews, 
             regression_data
            )

model6 %>% tidy(conf.int=TRUE)
model6 %>% glance()
```
> Nope

```{r}
# We know that superhost is not relevant, however, is it relevant if its intertwined with the review ratings?
model7 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + host_is_superhost*review_scores_rating, 
             regression_data
            )

model7 %>% tidy(conf.int=TRUE)
model7 %>% glance()
```
> Nope

next variable 

```{r}
model8 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact, 
             regression_data
            )

model8 %>% tidy(conf.int=TRUE)
model8 %>% glance()
```

We are missing the neightbourg stuff

```{r}
# model9 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy,
#              regression_data
#             )
# 
# model9 %>% tidy(conf.int=TRUE)
# model9 %>% glance()
```

We now add the cancellation policy stuff

```{r}
model10 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy,
             regression_data
            )

model10 %>% tidy(conf.int=TRUE)
model10 %>% glance()
```
> Cancelation policy does not seem to significantly affect the price

```{r}
huxreg(model3, model5, model8, model10,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')
```

```{r}

# regression_data %>% 
#   select(c(price_4_night, 
#            review_scores_cleanliness, security_deposit)) %>% 
# ggpairs()

model11 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy + review_scores_cleanliness, 
             regression_data
            )

model11 %>% tidy(conf.int=TRUE)
model11 %>% glance()

model12 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + cancellation_policy + instant_bookable,
             regression_data
            )

model12 %>% tidy(conf.int=TRUE)
model12 %>% glance()

model13 <- lm(price_4_night ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bedrooms + bathrooms + beds + accommodates + is_location_exact + security_deposit,
             regression_data
            )

model13 %>% tidy(conf.int=TRUE)
model13 %>% glance()

#################
huxreg(model11, model12, model13,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05, 
       stars = NULL
) %>% 
  set_caption('Comparison of models')

# 

car::vif(model1)
car::vif(model2)
car::vif(model13)

########### https://www.displayr.com/variance-inflation-factors-vifs/ USE THIS TO EXPLAIN - ex: beds/baths/accommodates - but none of the VIFs is high enough to suggest collinearity so we're good

```


## Diagnostics, collinearity, summary tables

```{r}

autoplot(model1)

```

```{r}

reading_week <- regression_data %>% 
  filter(prop_type_simplified=="Apartment", 
         room_type=="Private room", 
         number_of_reviews >=10,
         review_scores_rating >=90)

reading_week

set.seed(6789)

train_test_split <- initial_split(reading_week, prop=0.75)
reading_week_train <- training(train_test_split)
reading_week_test <- testing(train_test_split)

rmse_train <- reading_week_train %>% 
  mutate(
    predictions = predict(model1, .)
  ) %>% 
  summarise(
    sqrt(sum(predictions - price_4_night)**2/n())) %>% 
  pull()

rmse_train

rmse_test <- reading_week_test %>% 
  mutate(predictions = predict(model1, .)) %>% 
  summarise(
    sqrt(sum(predictions - price_4_night)**2/n())) %>% 
  pull()

rmse_test

```
